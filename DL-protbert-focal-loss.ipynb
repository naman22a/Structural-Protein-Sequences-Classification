{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd9ca6a-70cc-4927-885a-11b7a062cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b94da3e-043d-4657-8abb-df0d13329a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71573</th>\n",
       "      <td>XEWEALEKKLAALESKXQALEKKLEALEHGX</td>\n",
       "      <td>DE NOVO PROTEIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257713</th>\n",
       "      <td>GPGSMSIPTLNPTVALVAIDLQNGIVVLPMVPQSGGDVVAKTAELA...</td>\n",
       "      <td>UNKNOWN FUNCTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169619</th>\n",
       "      <td>ALLSFERKYRVPGGTLVGGNLFDFWVGPFYVGFFGVATFFFAALGI...</td>\n",
       "      <td>PHOTOSYNTHESIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13661</th>\n",
       "      <td>MGHHHHHHSGEDEQQEQTIAEDLVVTKYKMGGDIANRVLRSLVEAS...</td>\n",
       "      <td>TRANSCRIPTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60685</th>\n",
       "      <td>XFMAFWEXLX</td>\n",
       "      <td>CELL CYCLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sequence    classification\n",
       "71573                     XEWEALEKKLAALESKXQALEKKLEALEHGX   DE NOVO PROTEIN\n",
       "257713  GPGSMSIPTLNPTVALVAIDLQNGIVVLPMVPQSGGDVVAKTAELA...  UNKNOWN FUNCTION\n",
       "169619  ALLSFERKYRVPGGTLVGGNLFDFWVGPFYVGFFGVATFFFAALGI...    PHOTOSYNTHESIS\n",
       "13661   MGHHHHHHSGEDEQQEQTIAEDLVVTKYKMGGDIANRVLRSLVEAS...     TRANSCRIPTION\n",
       "60685                                          XFMAFWEXLX        CELL CYCLE"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/protein_data.csv')\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_sampled, _ = train_test_split(\n",
    "    data,\n",
    "    stratify=data['classification'],\n",
    "    # train_size=10_000,\n",
    "    train_size=20_000,\n",
    "    random_state=42\n",
    ")\n",
    "df_sampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c3f4ad9-c17c-489f-a19d-cd9c8124f16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85d33bcf-4ed1-4d7b-a3a2-ba69c7c28c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classification\n",
       "DE NOVO PROTEIN                            625\n",
       "UNKNOWN FUNCTION                           625\n",
       "SIGNALING PROTEIN                          625\n",
       "IMMUNE SYSTEM                              625\n",
       "STRUCTURAL GENOMICS, UNKNOWN FUNCTION      625\n",
       "OXIDOREDUCTASE/OXIDOREDUCTASE INHIBITOR    625\n",
       "CHAPERONE                                  625\n",
       "HYDROLASE                                  625\n",
       "LIGASE                                     625\n",
       "TRANSFERASE                                625\n",
       "GENE REGULATION                            625\n",
       "TRANSFERASE/TRANSFERASE INHIBITOR          625\n",
       "RNA BINDING PROTEIN                        625\n",
       "STRUCTURAL PROTEIN                         625\n",
       "PROTEIN TRANSPORT                          625\n",
       "CELL ADHESION                              625\n",
       "OXIDOREDUCTASE                             625\n",
       "PROTEIN BINDING                            625\n",
       "TRANSPORT PROTEIN                          625\n",
       "TOXIN                                      625\n",
       "DNA BINDING PROTEIN                        625\n",
       "VIRAL PROTEIN                              625\n",
       "METAL BINDING PROTEIN                      625\n",
       "SUGAR BINDING PROTEIN                      625\n",
       "MEMBRANE PROTEIN                           625\n",
       "ISOMERASE                                  625\n",
       "LYASE                                      625\n",
       "ELECTRON TRANSPORT                         625\n",
       "CELL CYCLE                                 625\n",
       "TRANSCRIPTION                              625\n",
       "PHOTOSYNTHESIS                             625\n",
       "HYDROLASE/HYDROLASE INHIBITOR              625\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled['classification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1db75d2-1cb6-48c3-908b-633f26172e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_sampled['sequence']\n",
    "y = df_sampled['classification']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "class_names = le.classes_\n",
    "n_classes = len(class_names)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6db6e9cc-cee9-4a51-ba16-40c19923e0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average character length: 241.07\n"
     ]
    }
   ],
   "source": [
    "avg_char_len = X_train.str.len().mean()\n",
    "print(f\"Average character length: {avg_char_len:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afae0115-e82b-400d-8397-820a1573c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "\n",
    "def preprocess_sequence(sequence):\n",
    "    return ' '.join(list(sequence.strip()))\n",
    "\n",
    "def tokenize_sequences(sequences, max_length=250):\n",
    "    sequences = [preprocess_sequence(seq) for seq in sequences]\n",
    "    return tokenizer(\n",
    "        sequences,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4971c02-b587-435d-945a-ae7c3c10320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, sequences, labels, max_length=250):\n",
    "        self.labels = labels\n",
    "        tokenized = tokenize_sequences(sequences, max_length=max_length)\n",
    "        self.input_ids = tokenized[\"input_ids\"]\n",
    "        self.attention_mask = tokenized[\"attention_mask\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "train_dataset = ProteinDataset(X_train.tolist(), y_train.tolist())\n",
    "val_dataset = ProteinDataset(X_val.tolist(), y_val.tolist())\n",
    "test_dataset = ProteinDataset(X_test.tolist(), y_test.tolist())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf68f09d-5abf-411e-b847-5b6752b8161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class ProteinClassifier(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.bert.config.hidden_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        x = self.dropout(pooled_output)\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10ae0be9-356b-4d53-a0b4-756aa0aae565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, delta=0, path=\"checkpoint.pt\", verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait after last improvement.\n",
    "            delta (float): Minimum change in monitored metric to qualify as improvement.\n",
    "            path (str): File path to save the best model.\n",
    "            verbose (bool): Print messages when improvement happens.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        \"\"\"Saves model when validation loss decreases.\"\"\"\n",
    "        if self.verbose:\n",
    "            print(f\"Validation loss decreased ({self.val_loss_min:.6f} → {val_loss:.6f}). Saving model...\")\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac5ed36b-4e06-4c3e-a4f0-970bd0446ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=None, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # tensor of class weights\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, weight=self.alpha, reduction=\"none\")\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0308b325-0697-4559-8cab-9c26f53bdbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e43f103c-caee-4003-85f5-e8efcd82832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# suppose y_train contains your training labels (numpy array)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c383ba1-6921-4b45-9977-eb53c2704dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim import AdamW\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ProteinClassifier(num_labels=n_classes).to(device)\n",
    "\n",
    "# Freeze BERT encoder\n",
    "# for param in model.bert.parameters():\n",
    "#     param.requires_grad = False\n",
    "for name, param in model.bert.named_parameters():\n",
    "    if \"encoder.layer.28\" in name or \"encoder.layer.29\" in name or \"encoder.layer.30\" in name or \"encoder.layer.31\" in name:\n",
    "        param.requires_grad = True   # unfreeze last 4 layers\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "optimizer = AdamW([\n",
    "    {\"params\": model.bert.parameters(), \"lr\": 2e-5},        # pretrained encoder (small LR)\n",
    "    {\"params\": model.classifier.parameters(), \"lr\": 1e-4},  # classifier head (larger LR)\n",
    "], weight_decay=0.01)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = FocalLoss(gamma=2, alpha=class_weights)\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "# History dictionary\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'epoch_time': []\n",
    "}\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True, path=\"./models/probert_focal_loss.pt\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_train_preds = []\n",
    "    all_train_labels = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_train_preds.extend(preds.cpu().numpy())\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_acc = accuracy_score(all_train_labels, all_train_preds)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_val_preds = []\n",
    "    all_val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_val_preds.extend(preds.cpu().numpy())\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(all_val_labels, all_val_preds)\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {total_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Time: {elapsed:.2f}s\")\n",
    "\n",
    "    # Save to history\n",
    "    history['train_loss'].append(total_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['epoch_time'].append(elapsed)\n",
    "\n",
    "    early_stopping(val_loss, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666f2f7-8579-4763-a27a-259250f90e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "plt.plot(history['val_loss'], label='Val Loss', marker='o')\n",
    "plt.legend()\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d5f90-64a5-4838-9e3a-0e373be5b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
    "plt.plot(history['val_acc'], label='Val Accuracy', marker='o')\n",
    "plt.title(\"Accuracy per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b8e5e-244d-47ac-a4b2-c2f7ad90b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_acc = accuracy_score(test_labels, test_preds)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9adef9c-8ec3-49fa-9b71-f1e2217bd7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c0d808-c4ec-4e30-983d-3104932c0c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_labels, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae3b01-8356-405f-a2fd-fec5fe178743",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc4d150-60e2-41ff-81da-406577f806c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
